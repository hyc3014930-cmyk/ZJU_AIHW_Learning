import math
import numpy as np
import os
import cv2
import random
import shutil
import time
from matplotlib import pyplot as plt
from easydict import EasyDict
from PIL import Image

import mindspore as ms
from mindspore import context
from mindspore import nn
from mindspore import Tensor
from mindspore.train.model import Model
from mindspore.train.serialization import load_checkpoint, save_checkpoint, export
from mindspore.train.callback import Callback, LossMonitor, ModelCheckpoint, CheckpointConfig

from src_mindspore.dataset import create_dataset # æ•°æ®å¤„ç†è„šæœ¬
from src_mindspore.mobilenetv2 import MobileNetV2Backbone, mobilenet_v2 # æ¨¡å‹å®šä¹‰è„šæœ¬

os.environ['GLOG_v'] = '2' # Log Level = Error
has_gpu = (os.system('command -v nvidia-smi') == 0)
print('Excuting with', 'GPU' if has_gpu else 'CPU', '.')
context.set_context(mode=context.GRAPH_MODE, device_target='GPU' if has_gpu else 'CPU')


# åƒåœ¾åˆ†ç±»æ•°æ®é›†æ ‡ç­¾ï¼Œä»¥åŠç”¨äºæ ‡ç­¾æ˜ å°„çš„å­—å…¸ã€‚
index = {'00_00': 0, '00_01': 1, '00_02': 2, '00_03': 3, '00_04': 4, '00_05': 5, '00_06': 6, '00_07': 7,
         '00_08': 8, '00_09': 9, '01_00': 10, '01_01': 11, '01_02': 12, '01_03': 13, '01_04': 14,
         '01_05': 15, '01_06': 16, '01_07': 17, '02_00': 18, '02_01': 19, '02_02': 20, '02_03': 21,
         '03_00': 22, '03_01': 23, '03_02': 24, '03_03': 25}
inverted = {0: 'Plastic Bottle', 1: 'Hats', 2: 'Newspaper', 3: 'Cans', 4: 'Glassware', 5: 'Glass Bottle', 6: 'Cardboard', 7: 'Basketball',
            8: 'Paper', 9: 'Metalware', 10: 'Disposable Chopsticks', 11: 'Lighter', 12: 'Broom', 13: 'Old Mirror', 14: 'Toothbrush',
            15: 'Dirty Cloth', 16: 'Seashell', 17: 'Ceramic Bowl', 18: 'Paint bucket', 19: 'Battery', 20: 'Fluorescent lamp', 21: 'Tablet capsules',
            22: 'Orange Peel', 23: 'Vegetable Leaf', 24: 'Eggshell', 25: 'Banana Peel'}

# è®­ç»ƒè¶…å‚
config = EasyDict({
    "num_classes": 26, # åˆ†ç±»æ•°ï¼Œå³è¾“å‡ºå±‚çš„ç»´åº¦
    "reduction": 'mean', # mean, max, Headéƒ¨åˆ†æ± åŒ–é‡‡ç”¨çš„æ–¹å¼
    "image_height": 224,
    "image_width": 224,
    "batch_size": 24, # é‰´äºCPUå®¹å™¨æ€§èƒ½ï¼Œå¤ªå¤§å¯èƒ½ä¼šå¯¼è‡´è®­ç»ƒå¡ä½
    "eval_batch_size": 10,
    "epochs": 1000, # è¯·å°è¯•ä¿®æ”¹ä»¥æå‡ç²¾åº¦
    "lr_max": 0.001, # è¯·å°è¯•ä¿®æ”¹ä»¥æå‡ç²¾åº¦
    "decay_type": 'square', # è¯·å°è¯•ä¿®æ”¹ä»¥æå‡ç²¾åº¦
    "momentum": 0.9, # è¯·å°è¯•ä¿®æ”¹ä»¥æå‡ç²¾åº¦
    "weight_decay": 0.001, # è¯·å°è¯•ä¿®æ”¹ä»¥æå‡ç²¾åº¦
    "dataset_path": "./datasets/5fbdf571c06d3433df85ac65-momodel/garbage_26x100",
    "features_path": "./results/garbage_26x100_features", # ä¸´æ—¶ç›®å½•ï¼Œä¿å­˜å†»ç»“å±‚Feature Mapï¼Œå¯éšæ—¶åˆ é™¤
    "class_index": index,
    "save_ckpt_epochs": 1,
    "save_ckpt_path": './results/ckpt_mobilenetv2',
    "pretrained_ckpt": './src_mindspore/mobilenetv2-200_1067_cpu_gpu.ckpt',
    "export_path": './results/mobilenetv2.mindir'

})


result = []
ds = create_dataset(config=config, training=False)
data_iterator = ds.create_dict_iterator(output_numpy=True)
for i, data in enumerate(data_iterator):
    if i >= 4:  # åªæ˜¾ç¤ºå‰å››ä¸ªå›¾åƒ
        break
    images = data['image'][0]
    labels = data['label'][0]
    
    plt.subplot(2, 2, i + 1)
    plt.imshow(np.transpose(images, (1, 2, 0)))  # ç¡®ä¿ç»´åº¦æ­£ç¡®
    plt.title('label: %s' % inverted[labels])
    plt.xticks([])

plt.show()

def build_lr(total_steps, lr_init=0.0, lr_end=0.0, lr_max=0.1, warmup_steps=0, decay_type='cosine'):
    """
    Applies cosine decay to generate learning rate array.

    Args:
       total_steps(int): all steps in training.
       lr_init(float): init learning rate.
       lr_end(float): end learning rate
       lr_max(float): max learning rate.
       warmup_steps(int): all steps in warmup epochs.

    Returns:
       list, learning rate array.
    """
    lr_init, lr_end, lr_max = float(lr_init), float(lr_end), float(lr_max)
    decay_steps = total_steps - warmup_steps
    lr_all_steps = []
    inc_per_step = (lr_max - lr_init) / warmup_steps if warmup_steps else 0
    for i in range(total_steps):
        if i < warmup_steps:
            lr = lr_init + inc_per_step * (i + 1)
        else:
            if decay_type == 'cosine':
                cosine_decay = 0.5 * (1 + math.cos(math.pi * (i - warmup_steps) / decay_steps))
                lr = (lr_max - lr_end) * cosine_decay + lr_end
            elif decay_type == 'square':
                frac = 1.0 - float(i - warmup_steps) / (total_steps - warmup_steps)
                lr = (lr_max - lr_end) * (frac * frac) + lr_end
            else:
                lr = lr_max
        lr_all_steps.append(lr)

    return lr_all_steps


steps = 5*93
plt.plot(range(steps), build_lr(steps, lr_max=0.1, decay_type='constant'))
plt.plot(range(steps), build_lr(steps, lr_max=0.1, decay_type='square'))
plt.plot(range(steps), build_lr(steps, lr_max=0.1, decay_type='cosine'))
plt.show()


def extract_features(net, dataset_path, config):
    if not os.path.exists(config.features_path):
        os.makedirs(config.features_path)
    dataset = create_dataset(config=config)
    step_size = dataset.get_dataset_size()
    if step_size == 0:
        raise ValueError("The step_size of dataset is zero. Check if the images count of train dataset is more \
            than batch_size in config.py")

    data_iter = dataset.create_dict_iterator()
    for i, data in enumerate(data_iter):
        features_path = os.path.join(config.features_path, f"feature_{i}.npy")
        label_path = os.path.join(config.features_path, f"label_{i}.npy")
        if not os.path.exists(features_path) or not os.path.exists(label_path):
            image = data["image"]
            label = data["label"]
            features = net(image)
            np.save(features_path, features.asnumpy())
            np.save(label_path, label.asnumpy())
        print(f"Complete the batch {i+1}/{step_size}")
    return

backbone = MobileNetV2Backbone()
load_checkpoint(config.pretrained_ckpt, net=backbone)
extract_features(backbone, config.dataset_path, config)


class GlobalPooling(nn.Cell):
    """
    Global avg pooling definition.

    Args:
        reduction: mean or max, which means AvgPooling or MaxpPooling.

    Returns:
        Tensor, output tensor.

    Examples:
        >>> GlobalAvgPooling()
    """

    def __init__(self, reduction='mean'):
        super(GlobalPooling, self).__init__()
        if reduction == 'max':
            self.mean = ms.ops.ReduceMax(keep_dims=False)
        else:
            self.mean = ms.ops.ReduceMean(keep_dims=False)

    def construct(self, x):
        x = self.mean(x, (2, 3))
        return x


class MobileNetV2Head(nn.Cell):
    """
    MobileNetV2Head architecture.

    Args:
        input_channel (int): Number of channels of input.
        hw (int): Height and width of input, 7 for MobileNetV2Backbone with image(224, 224).
        num_classes (int): Number of classes. Default is 1000.
        reduction: mean or max, which means AvgPooling or MaxpPooling.
        activation: Activation function for output logits.
    Returns:
        Tensor, output tensor.

    Examples:
        >>> MobileNetV2Head(num_classes=1000)
    """

    def __init__(self, input_channel=1280, hw=7, num_classes=1000, reduction='mean', activation="None"):
        super(MobileNetV2Head, self).__init__()
        self.need_activation = True
        if reduction:
            self.flatten = GlobalPooling(reduction)
        else:
            self.flatten = nn.Flatten()
            input_channel = input_channel * hw * hw
        self.dense = nn.Dense(input_channel, num_classes, weight_init='ones', has_bias=False)
        if activation == "Sigmoid":
            self.activation = nn.Sigmoid()
        elif activation == "Softmax":
            self.activation = nn.Softmax()
        else:
            self.need_activation = False

    def construct(self, x):
        x = self.flatten(x)
        x = self.dense(x)
        if self.need_activation:
            x = self.activation(x)
        return x


def train_head():
    train_dataset = create_dataset(config=config)
    eval_dataset = create_dataset(config=config)
    step_size = train_dataset.get_dataset_size()

    backbone = MobileNetV2Backbone()
    # Freeze parameters of backbone. You can comment these two lines.
    for param in backbone.get_parameters():
        param.requires_grad = False
    load_checkpoint(config.pretrained_ckpt, net=backbone)

    head = MobileNetV2Head(input_channel=backbone.out_channels, num_classes=config.num_classes, reduction=config.reduction)
    network = mobilenet_v2(backbone, head)

    loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')
    lrs = build_lr(config.epochs * step_size, lr_max=config.lr_max, warmup_steps=0, decay_type=config.decay_type)
    opt = nn.Momentum(head.trainable_params(), lrs, config.momentum, config.weight_decay)
    net = nn.WithLossCell(head, loss)
    train_step = nn.TrainOneStepCell(net, opt)
    train_step.set_train()

    # train
    history = list()
    features_path = config.features_path
    idx_list = list(range(step_size))
    for epoch in range(config.epochs):
        random.shuffle(idx_list)
        epoch_start = time.time()
        losses = []
        for j in idx_list:
            feature = Tensor(np.load(os.path.join(features_path, f"feature_{j}.npy")))
            label = Tensor(np.load(os.path.join(features_path, f"label_{j}.npy")))
            losses.append(train_step(feature, label).asnumpy())
        epoch_seconds = (time.time() - epoch_start)
        epoch_loss = np.mean(np.array(losses))

        history.append(epoch_loss)
        print("epoch: {}, time cost: {}, avg loss: {}".format(epoch + 1, epoch_seconds, epoch_loss))
        if (epoch + 1) % config.save_ckpt_epochs == 0:
            save_checkpoint(network, os.path.join(config.save_ckpt_path, f"mobilenetv2-{epoch+1}.ckpt"))

    # evaluate
    print('validating the model...')
    eval_model = Model(network, loss, metrics={'acc', 'loss'})
    acc = eval_model.eval(eval_dataset, dataset_sink_mode=False)
    print(acc)

    return history


if os.path.exists(config.save_ckpt_path):
    shutil.rmtree(config.save_ckpt_path)
os.makedirs(config.save_ckpt_path)

history = train_head()

plt.plot(history, label='train_loss')
plt.legend()
plt.show()

CKPT = f'mobilenetv2-{config.epochs}.ckpt'
print("Chosen checkpoint is", CKPT)


def image_process(image):
    """Precess one image per time.

    Args:
        image: shape (H, W, C)
    """
    mean=[0.485*255, 0.456*255, 0.406*255]
    std=[0.229*255, 0.224*255, 0.225*255]
    image = (np.array(image) - mean) / std
    image = image.transpose((2,0,1))
    img_tensor = Tensor(np.array([image], np.float32))
    return img_tensor

def infer_one(network, image_path):
    image = Image.open(image_path).resize((config.image_height, config.image_width))
    logits = network(image_process(image))
    pred = np.argmax(logits.asnumpy(), axis=1)[0]
    print(image_path, inverted[pred])
    return pred

def infer(images):
    backbone = MobileNetV2Backbone()
    head = MobileNetV2Head(input_channel=backbone.out_channels, num_classes=config.num_classes, reduction=config.reduction)
    network = mobilenet_v2(backbone, head)
    print('åŠ è½½æ¨¡å‹è·¯å¾„:',os.path.join(config.save_ckpt_path, CKPT))
    load_checkpoint(os.path.join(config.save_ckpt_path, CKPT), net=network)
    for img in images:
        infer_one(network, img)


test_images = list()
folder = os.path.join(config.dataset_path, 'val/00_01') # Hats
for img in os.listdir(folder):
    test_images.append(os.path.join(folder, img))

infer(test_images)


## ç”Ÿæˆ main.py æ—¶è¯·å‹¾é€‰æ­¤ cell 

# æœ¬ç¤ºèŒƒä»¥ NoteBook è®­ç»ƒæ¨¡å‹é€šè¿‡å¹³å°æµ‹è¯•ä¸ºä¾‹ï¼š

# 1. å¯¼å…¥ç›¸å…³åŒ…
import os
import cv2
import numpy as np
from PIL import Image
import mindspore as ms
from mindspore import nn, Tensor
from easydict import EasyDict
from mindspore import context
from mindspore.train.serialization import load_checkpoint

from src_mindspore.mobilenetv2 import MobileNetV2Backbone, mobilenet_v2 # æ¨¡å‹å®šä¹‰è„šæœ¬

os.environ['GLOG_v'] = '2'  # Log Level = Error
has_gpu = (os.system('command -v nvidia-smi') == 0)
print('Excuting with', 'GPU' if has_gpu else 'CPU', '.')
context.set_context(mode=context.GRAPH_MODE, device_target='GPU' if has_gpu else 'CPU')

# 2.ç³»ç»Ÿæµ‹è¯•éƒ¨åˆ†æ ‡ç­¾ä¸è¯¥å¤„ä¸€è‡´ï¼Œè¯·ä¸è¦æ”¹åŠ¨
index = {'00_00': 0, '00_01': 1, '00_02': 2, '00_03': 3, '00_04': 4, '00_05': 5, '00_06': 6, '00_07': 7,
         '00_08': 8, '00_09': 9, '01_00': 10, '01_01': 11, '01_02': 12, '01_03': 13, '01_04': 14,
         '01_05': 15, '01_06': 16, '01_07': 17, '02_00': 18, '02_01': 19, '02_02': 20, '02_03': 21,
         '03_00': 22, '03_01': 23, '03_02': 24, '03_03': 25}

inverted = {0: 'Plastic Bottle', 1: 'Hats', 2: 'Newspaper', 3: 'Cans', 4: 'Glassware', 5: 'Glass Bottle', 6: 'Cardboard', 7: 'Basketball',
            8: 'Paper', 9: 'Metalware', 10: 'Disposable Chopsticks', 11: 'Lighter', 12: 'Broom', 13: 'Old Mirror', 14: 'Toothbrush',
            15: 'Dirty Cloth', 16: 'Seashell', 17: 'Ceramic Bowl', 18: 'Paint bucket', 19: 'Battery', 20: 'Fluorescent lamp', 21: 'Tablet capsules',
            22: 'Orange Peel', 23: 'Vegetable Leaf', 24: 'Eggshell', 25: 'Banana Peel'}

# 3. æ¨¡å‹å‚æ•°
config = EasyDict({
    "num_classes": 26,
    "reduction": 'mean',
    "image_height": 224,
    "image_width": 224,
    "eval_batch_size": 10
})

# 4. è‡ªå®šä¹‰Headéƒ¨åˆ†ï¼ˆä¿®å¤ need_activation BUGï¼‰
class GlobalPooling(nn.Cell):
    def __init__(self, reduction='mean'):
        super(GlobalPooling, self).__init__()
        if reduction == 'max':
            self.pool = ms.ops.ReduceMax(keep_dims=False)
        else:
            self.pool = ms.ops.ReduceMean(keep_dims=False)

    def construct(self, x):
        return self.pool(x, (2, 3))

class MobileNetV2Head(nn.Cell):
    def __init__(self, input_channel=1280, hw=7, num_classes=1000, reduction='mean', activation="None"):
        super(MobileNetV2Head, self).__init__()
        if reduction:
            self.flatten = GlobalPooling(reduction)
            input_channel = input_channel
        else:
            self.flatten = nn.Flatten()
            input_channel = input_channel * hw * hw
        self.dense = nn.Dense(input_channel, num_classes)

        self.need_activation = activation in ["Sigmoid", "Softmax"]
        if activation == "Sigmoid":
            self.activation = nn.Sigmoid()
        elif activation == "Softmax":
            self.activation = nn.Softmax()

    def construct(self, x):
        x = self.flatten(x)
        x = self.dense(x)
        if self.need_activation:
            x = self.activation(x)
        return x

# 5. åŠ è½½æ¨¡å‹
backbone = MobileNetV2Backbone()
head = MobileNetV2Head(input_channel=backbone.out_channels, num_classes=config.num_classes, reduction=config.reduction)
network = mobilenet_v2(backbone, head)

model_path = './results/ckpt_mobilenetv2/mobilenetv2-500.ckpt'
load_checkpoint(model_path, net=network)
network.set_train(False)  # âœ…é‡è¦ï¼šæ¨ç†æ¨¡å¼

# ---------------------------------------------------------------------------

# ---------------------------------------------------------------------------
# ğŸš€ æ”¹è¿›åçš„æ¨ç†é¢„å¤„ç†ï¼ˆå®Œå…¨å…¼å®¹ï¼Œä¸è§¦å‘ä»»ä½• import é”™è¯¯ï¼‰
# ---------------------------------------------------------------------------

def image_process(image):
    """
    æ›´è´´è¿‘è®­ç»ƒè®¾ç½®çš„é¢„å¤„ç†æ­¥éª¤ï¼š
    - ä¿è¯ä½¿ç”¨ PIL çš„ RGB æ ¼å¼
    - resize â†’ é™¤255 â†’ normalize â†’ CHW
    """

    # --- 1. ç¡®ä¿é¢œè‰²é€šé“æ­£ç¡® ---
    img = Image.fromarray(image).convert('RGB')

    # --- 2. Resizeï¼ˆä¸è®­ç»ƒä¿æŒä¸€è‡´ï¼‰ ---
    img = img.resize((config.image_width, config.image_height), Image.BILINEAR)

    # --- 3. è½¬ numpy å¹¶é™¤ä»¥ 255 ---
    img = np.array(img).astype(np.float32) / 255.0

    # --- 4. Normalize ---
    mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)
    std  = np.array([0.229, 0.224, 0.225], dtype=np.float32)
    img = (img - mean) / std

    # --- 5. HWC â†’ CHW ---
    img = img.transpose(2, 0, 1)

    # --- 6. åŠ  batch ç»´åº¦ ---
    return Tensor(img[None, ...], ms.float32)


def predict(image):
    """
    åªå¯¹è¾“å…¥è¿›è¡Œé¢„å¤„ç† + æ¨ç† + å–æœ€å¤§å€¼
    """
    img_tensor = image_process(image)
    logits = network(img_tensor)

    pred = int(np.argmax(logits.asnumpy(), axis=1)[0])
    return inverted[pred]


# æµ‹è¯•ç¤ºä¾‹
image_path = './datasets/5fbdf571c06d3433df85ac65-momodel/garbage_26x100/val/00_01/00037.jpg'
image = np.array(Image.open(image_path))
print(predict(image))


